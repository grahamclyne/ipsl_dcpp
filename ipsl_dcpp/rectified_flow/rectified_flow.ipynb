{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate \n",
    "\n",
    "from ipsl_dcpp.model.ipsl_dataset import IPSL_DCPP\n",
    "import torch\n",
    "import lightning as pl\n",
    "from ipsl_dcpp.model.pangu import PanguWeather\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['SLURM_NTASKS_PER_NODE'] = '1'\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "pl.seed_everything(cfg.experiment.seed)\n",
    "\n",
    "train = hydra.utils.instantiate(\n",
    "    cfg.experiment.train_dataset,\n",
    "    generate_statistics=False,\n",
    "    surface_variables=cfg.experiment.surface_variables,\n",
    "    depth_variables=cfg.experiment.depth_variables,\n",
    "    plev_variables=cfg.experiment.plev_variables,\n",
    "    work_path=cfg.environment.work_path,\n",
    "    scratch_path=cfg.environment.scratch_path,\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=(1,143,144), hidden_num=144):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_num, bias=True)\n",
    "        self.fc2 = nn.Linear(hidden_num, hidden_num, bias=True)\n",
    "        self.fc3 = nn.Linear(hidden_num, input_dim, bias=True)\n",
    "        self.act = lambda x: torch.tanh(x)\n",
    "\n",
    "    def forward(self, x_input, t):\n",
    "\n",
    "        inputs = torch.cat([x_input, t], dim=0)\n",
    "      #  print(inputs.shape)\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x.mean(dim=0)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate X_0 (noise) and X_1 (image) pairs\n",
    "\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.experiment.module,\n",
    "    backbone=hydra.utils.instantiate(\n",
    "        cfg.experiment.backbone,\n",
    "    ),\n",
    "    dataset=train_dataloader.dataset\n",
    ")\n",
    "\n",
    "\n",
    "checkpoint_path = torch.load(f'../epoch=30.ckpt',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint_path['state_dict'])\n",
    "# trainer.test(model, val_dataloader)\n",
    "# inv_map = {v: k for k, v in val.id2pt.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "pairs = []\n",
    "for i in range(5):\n",
    "    image = model.sample(batch, denormalize=False,num_inference_steps=model.num_inference_steps,scheduler=model.scheduler)\n",
    "    pairs.append((image[0],image[-1]))\n",
    "import pickle \n",
    "output = open('rectified_flow_pairs.pkl', 'wb')\n",
    "\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(pairs, output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_ = [(x[0]['state_surface'],x[1]) for x in pairs]\n",
    "images = torch.stack([x[0] for x in pairs_])\n",
    "noise = torch.stack([x[1] for x in pairs_])\n",
    "pairs_ = torch.stack([images,noise],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_var = images[0,0,0,:,:].reshape(1,-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(image_var[:,:5000],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectifiedFlow():\n",
    "  def __init__(self, model=None, num_steps=1000):\n",
    "    self.model = model\n",
    "    self.N = num_steps\n",
    "\n",
    "  def get_train_tuple(self, z0=None, z1=None):\n",
    " #   print(z0.shape)\n",
    " #   print(z1.shape)\n",
    "    t = torch.rand((z1.shape[0], 143,144))\n",
    "#    print(t.shape)\n",
    "    z_t =  t * z1 + (1.-t) * z0\n",
    "    target = z1 - z0\n",
    "\n",
    "    return z_t, t, target\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def sample_ode(self, z0=None, N=None):\n",
    "    ### NOTE: Use Euler method to sample from the learned flow\n",
    "    if N is None:\n",
    "      N = self.N\n",
    "    dt = 1./N\n",
    "    traj = [] # to store the trajectory\n",
    "    z = z0.detach().clone()\n",
    "    batchsize = z.shape[0]\n",
    "\n",
    "    traj.append(z.detach().clone())\n",
    "    for i in range(N):\n",
    "      t = torch.ones((batchsize,143,144)) * i / N\n",
    "    #  print(z.shape)\n",
    "    #  print(t.shape) \n",
    "      pred = self.model(z, t)\n",
    "    #  print('pred',pred.shape)\n",
    "    #  print(z.shape)\n",
    "    #  print(dt)\n",
    "      z = z.detach().clone() + pred * dt\n",
    "      \n",
    "      traj.append(z.detach().clone())\n",
    "    #  print(len(traj),'traj length')\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rectified_flow(rectified_flow, optimizer, pairs, batchsize, inner_iters):\n",
    "  loss_curve = []\n",
    "  for i in range(inner_iters+1):\n",
    "    optimizer.zero_grad()\n",
    "    indices = torch.randperm(len(pairs))[:batchsize]\n",
    "  #  print(indices)\n",
    "    batch = pairs[indices][0]\n",
    "  #  print(batch.shape)\n",
    "    z0 = batch[0].detach().clone()\n",
    "    z1 = batch[1].detach().clone()\n",
    "    z_t, t, target = rectified_flow.get_train_tuple(z0=z0, z1=z1)\n",
    "\n",
    "    pred = rectified_flow.model(z_t, t)\n",
    "   # print(pred.shape)\n",
    "    loss = (target - pred).view(pred.shape[0], -1).abs().pow(2).sum(dim=1)\n",
    "    loss = loss.mean()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    loss_curve.append(np.log(loss.item())) ## to store the loss curve\n",
    "\n",
    "  return rectified_flow, loss_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 5000\n",
    "batchsize = 1\n",
    "import matplotlib.pyplot as plt\n",
    "rectified_flow_1 = RectifiedFlow(model=model.backbone, num_steps=4000)\n",
    "optimizer = torch.optim.Adam(rectified_flow_1.model.parameters(), lr=5e-3)\n",
    "\n",
    "rectified_flow_1, loss_curve = train_rectified_flow(rectified_flow_1, optimizer, pairs, batchsize, iterations)\n",
    "plt.plot(np.linspace(0, iterations, iterations+1), loss_curve[:(iterations+1)])\n",
    "plt.title('Training Loss Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10.\n",
    "M = D+5\n",
    "\n",
    "@torch.no_grad()\n",
    "def draw_plot(rectified_flow, z0, z1, N=None):\n",
    "  traj = rectified_flow.sample_ode(z0=z0, N=N)\n",
    "  print(len(traj))\n",
    "  plt.figure(figsize=(4,4))\n",
    "  plt.xlim(-M,M)\n",
    "  plt.ylim(-M,M)\n",
    "  \n",
    "  plt.scatter(z1[:, 0].cpu().numpy(), z1[:, 1].cpu().numpy(), label=r'$\\pi_1$', alpha=0.15)\n",
    "  plt.scatter(z0[:, 0].cpu().numpy(), z0[:, 1].cpu().numpy(), label=r'$\\pi_0$', alpha=0.15)\n",
    "  plt.scatter(traj[-1][:, 0].cpu().numpy(), traj[-1][:, 1].cpu().numpy(), label='Generated', alpha=0.15)\n",
    "  plt.legend()\n",
    "  plt.title('Distribution')\n",
    "  plt.tight_layout()\n",
    "\n",
    "  traj_particles = torch.stack(traj)\n",
    "  print('particles',traj_particles.shape)\n",
    "  traj_particles = traj_particles.reshape(101,143*144)\n",
    "  plt.figure(figsize=(4,4))\n",
    "  plt.xlim(-M,M)\n",
    "  plt.ylim(-M,M)\n",
    "  print(traj_particles.shape)\n",
    "  plt.axis('equal')\n",
    "  for i in range(143*144):\n",
    "    plt.plot(traj_particles[:,i], traj_particles[:,i])\n",
    "  plt.title('Transport Trajectory')\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[:,0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pairs[0,0]\n",
    "noise = pairs[0,1]\n",
    "# i = images.swapaxes(2,-1).reshape(10*143*144,9)\n",
    "# n = noise.swapaxes(2,-1).reshape(10*143*144,9)\n",
    "draw_plot(rectified_flow_1, z0=images, z1=noise, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
