{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n",
      "9it [00:01,  5.25it/s]\n",
      "/Users/gclyne/miniforge3/envs/env_dcpp/lib/python3.12/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025535429/work/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "#rectified flow from https://github.com/grahamclyne/RectifiedFlow/tree/main\n",
    "\n",
    "#load score based model AND datasets\n",
    "\n",
    "#generate \n",
    "\n",
    "from ipsl_dcpp.model.ipsl_dataset import IPSL_DCPP\n",
    "import torch\n",
    "import lightning as pl\n",
    "from ipsl_dcpp.model.pangu import PanguWeather\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['SLURM_NTASKS_PER_NODE'] = '1'\n",
    "with initialize(version_base=None, config_path=\"conf\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "pl.seed_everything(cfg.experiment.seed)\n",
    "\n",
    "train = hydra.utils.instantiate(\n",
    "    cfg.experiment.train_dataset,\n",
    "    generate_statistics=False,\n",
    "    surface_variables=cfg.experiment.surface_variables,\n",
    "    depth_variables=cfg.experiment.depth_variables,\n",
    "    plev_variables=cfg.experiment.plev_variables,\n",
    "    work_path=cfg.environment.work_path,\n",
    "    scratch_path=cfg.environment.scratch_path,\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "checkpoint_path = torch.load(f'epoch=30.ckpt',map_location=torch.device('cpu'))\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.experiment.module,\n",
    "    backbone=hydra.utils.instantiate(cfg.experiment.backbone),\n",
    "    dataset=train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init. Distribution Variance: 1\n",
      "SDE Sampler Variance: 0.0\n",
      "ODE Tolerence: 1e-05\n"
     ]
    }
   ],
   "source": [
    "import ipsl_dcpp.sde_lib as sde_lib\n",
    "sde = sde_lib.RectifiedFlow(init_type='gaussian', noise_scale=1, use_ode_sampler='rk45')\n",
    "sampling_eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipsl_dcpp.losses as losses\n",
    "import ml_collections\n",
    "config = ml_collections.ConfigDict()\n",
    "\n",
    "config.optim = optim = ml_collections.ConfigDict()\n",
    "optim.weight_decay = 0.\n",
    "optim.optimizer = 'Adam'\n",
    "optim.lr = 2e-4\n",
    "optim.beta1 = 0.9\n",
    "optim.eps = 1e-8\n",
    "optim.warmup = 5000\n",
    "optim.grad_clip = 1.\n",
    "\n",
    "optimize_fn = losses.optimization_manager(config)\n",
    "\n",
    "train_step_fn = losses.get_step_fn(sde, train=True, optimize_fn=optimize_fn,\n",
    "                                    reduce_mean=False, continuous=False,\n",
    "                                    likelihood_weighting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipsl_dcpp.ema import ExponentialMovingAverage\n",
    "#for step in range(initial_step, num_train_steps + 1):\n",
    "train_iter = iter(train_dataloader)\n",
    "ema = ExponentialMovingAverage(model.parameters(), decay=0.999999)\n",
    "optimizer = losses.get_optimizer(config, model.parameters())\n",
    "state = dict(optimizer=optimizer, model=model, ema=ema, step=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 143, 144])\n",
      "torch.Size([1])\n",
      "tensor([0.6372])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_iter)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# batch = torch.from_numpy(next(train_iter)['image']._numpy()).to(config.device).float()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# batch = batch.permute(0, 3, 1, 2)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# batch = scaler(batch)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Execute one training step\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m~/ipsl_dcpp/ipsl_dcpp/losses.py:181\u001b[0m, in \u001b[0;36mget_step_fn.<locals>.step_fn\u001b[0;34m(state, batch)\u001b[0m\n\u001b[1;32m    179\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    180\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 181\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    183\u001b[0m optimize_fn(optimizer, model\u001b[38;5;241m.\u001b[39mparameters(), step\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/ipsl_dcpp/ipsl_dcpp/losses.py:110\u001b[0m, in \u001b[0;36mget_rectified_flow_loss_fn.<locals>.loss_fn\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m#model_fn = mutils.get_model_fn(model, train=train)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m model_fn \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward\n\u001b[0;32m--> 110\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m999\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m### Copy from models/utils.py \u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sde\u001b[38;5;241m.\u001b[39mreflow_flag:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m### we found LPIPS loss is the best for distillation when k=1; but good to have a try\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sde\u001b[38;5;241m.\u001b[39mreflow_loss\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;66;03m### train new rectified flow with reflow or distillation with L2 loss\u001b[39;00m\n",
      "File \u001b[0;32m~/ipsl_dcpp/ipsl_dcpp/model/simple_diffusion.py:64\u001b[0m, in \u001b[0;36mSimpleDiffusion.forward\u001b[0;34m(self, batch, timesteps, sel)\u001b[0m\n\u001b[1;32m     62\u001b[0m    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, timesteps, sel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m        device \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_surface\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     65\u001b[0m        bs \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_surface\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     66\u001b[0m      \u001b[38;5;66;03m#  print(sel.shape)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#       print(batch['surface_noisy'].shape)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#       print(batch['state_surface'].shape)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#       print(batch['state_constant'].shape)      \u001b[39;00m\n\u001b[1;32m     70\u001b[0m       \u001b[38;5;66;03m# batch['surface_noisy'] = batch['surface_noisy'].squeeze(1)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "for step in range(0, 10):\n",
    "\n",
    "  # Convert data to JAX arrays and normalize them. Use ._numpy() to avoid copy.\n",
    "  batch = next(train_iter)\n",
    "  # batch = torch.from_numpy(next(train_iter)['image']._numpy()).to(config.device).float()\n",
    "  # batch = batch.permute(0, 3, 1, 2)\n",
    "  # batch = scaler(batch)\n",
    "  # Execute one training step\n",
    "  loss = train_step_fn(state, batch)\n",
    "  print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dcpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
