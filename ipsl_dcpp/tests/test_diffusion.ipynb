{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n",
      "/Users/gclyne/miniforge3/envs/env_dcpp/lib/python3.12/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025535429/work/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "/Users/gclyne/miniforge3/envs/env_dcpp/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/gclyne/miniforge3/envs/env_dcpp/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "from ipsl_dcpp.model.ipsl_dataset import IPSL_DCPP\n",
    "import torch\n",
    "import lightning as pl\n",
    "from ipsl_dcpp.model.pangu import PanguWeather\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import hydra\n",
    "import os\n",
    "os.environ['SLURM_NTASKS_PER_NODE'] = '1'\n",
    "torch.set_default_dtype(torch.float32)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "#torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "pl.seed_everything(cfg.experiment.seed)\n",
    "train = hydra.utils.instantiate(\n",
    "    cfg.experiment.train_dataset,\n",
    "    generate_statistics=False,\n",
    "    surface_variables=cfg.experiment.surface_variables,\n",
    "    depth_variables=cfg.experiment.depth_variables,\n",
    "    plev_variables=cfg.experiment.plev_variables,\n",
    "    work_path=cfg.environment.work_path,\n",
    "    scratch_path=cfg.environment.scratch_path,\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "val = hydra.utils.instantiate(\n",
    "    cfg.experiment.val_dataset,\n",
    "    generate_statistics=False,\n",
    "    surface_variables=cfg.experiment.surface_variables,\n",
    "    depth_variables=cfg.experiment.depth_variables,\n",
    "    plev_variables=cfg.experiment.plev_variables,\n",
    "    work_path=cfg.environment.work_path,\n",
    "    scratch_path=cfg.environment.scratch_path,\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "#batch = next(iter(train_dataloader))\n",
    "model = hydra.utils.instantiate(\n",
    "    cfg.experiment.module,\n",
    "    backbone=hydra.utils.instantiate(\n",
    "        cfg.experiment.backbone,\n",
    "    ),\n",
    "    dataset=train_dataloader.dataset\n",
    "\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=cfg.experiment.max_epochs,\n",
    "    enable_checkpointing=True,\n",
    "    log_every_n_steps=1,\n",
    "   # max_steps=cfg.experiment.max_steps if not cfg.debug else 10,\n",
    "    precision=\"16-mixed\",\n",
    "    #precision='32',\n",
    "    profiler='simple' if cfg.debug else None,\n",
    "   # devices=cfg.experiment.num_gpus,\n",
    "   # strategy='ddp_find_unused_parameters_true',\n",
    "    #limit_train_batches=0.01 if cfg.debug else 1\n",
    "    #limit_val_batches=0.01 if cfg.debug else 1,\n",
    "    num_sanity_val_steps=1,\n",
    "  #  device='cpu',\n",
    "  #accelerator='mps',\n",
    "  #CONV3D not supported by mps, have to use cpu when local \n",
    "    accelerator= 'mps' if cfg.environment.name == 'local' else 'gpu',\n",
    "    fast_dev_run=1,\n",
    "    limit_val_batches=0.001,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gclyne/miniforge3/envs/env_dcpp/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f49193bc4444fd6b4ace2bd40d0f8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gclyne/miniforge3/envs/env_dcpp/lib/python3.12/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tas_err', 'tas_var', 'tas_spskr', 'tas_crps', 'gpp_err', 'gpp_var', 'gpp_spskr', 'gpp_crps', 'cVeg_err', 'cVeg_var', 'cVeg_spskr', 'cVeg_crps', 'evspsbl_err', 'evspsbl_var', 'evspsbl_spskr', 'evspsbl_crps', 'ps_err', 'ps_var', 'ps_spskr', 'ps_crps'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tas_err': tensor(12.0633),\n",
       " 'tas_var': tensor(5.9191e-07),\n",
       " 'tas_spskr': tensor(0.0002),\n",
       " 'tas_crps': tensor(2.3939),\n",
       " 'gpp_err': tensor(2.6501e-17),\n",
       " 'gpp_var': tensor(6.2836e-24),\n",
       " 'gpp_spskr': tensor(0.0005),\n",
       " 'gpp_crps': tensor(2.8582e-09),\n",
       " 'cVeg_err': tensor(0.0011),\n",
       " 'cVeg_var': tensor(2.1153e-10),\n",
       " 'cVeg_spskr': tensor(0.0005),\n",
       " 'cVeg_crps': tensor(0.0231),\n",
       " 'evspsbl_err': tensor(2.6537e-11),\n",
       " 'evspsbl_var': tensor(8.4090e-18),\n",
       " 'evspsbl_spskr': tensor(0.0006),\n",
       " 'evspsbl_crps': tensor(3.0864e-06),\n",
       " 'ps_err': tensor(315111.0312),\n",
       " 'ps_var': tensor(0.0361),\n",
       " 'ps_spskr': tensor(0.0004),\n",
       " 'ps_crps': tensor(343.9454)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.lightning_module.metrics.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(nan), tensor(nan))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = torch.tensor([[1,2,3,4,5,6,7,8,9,torch.nan],[1,2,3,4,5,6,7,8,torch.nan,10]])\n",
    "x.var(),x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_dataloader)\n",
    "trainer.logged_metrics\n",
    "# checkpoint_path = torch.load(f'../epoch=00.ckpt',map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(checkpoint_path['state_dict'])\n",
    "#trainer.test(model, val_dataloader)\n",
    "# batch = next(iter(val_dataloader))\n",
    "#history = model.sample_rollout(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample,batch,steps = model.sample(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "#get shell\n",
    "ds = xr.open_dataset(train.files[0])\n",
    "shell = ds.isel(time=0)\n",
    "var_name = 'gpp'\n",
    "var_index = cfg.experiment.surface_variables.index(var_name)\n",
    "\n",
    "#plot lat lon map of first rollout\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "#shell[var_name].data = steps[49][0,0,0]\n",
    "shell[var_name].data = batch['next_state_surface'][0][4]\n",
    "shell[var_name].plot.pcolormesh(ax=ax1)\n",
    "shell[var_name].data = sample['next_state_surface'][0][4]\n",
    "shell[var_name].plot.pcolormesh(ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from celluloid import Camera\n",
    "# fig, ax1 = plt.subplots(1, figsize=(16, 6))\n",
    "# camera = Camera(fig)\n",
    "# ax1.set_title(\"diffusion steps\")\n",
    "# ds = xr.open_dataset(val.files[0])\n",
    "# shell = ds.isel(time=0)\n",
    "\n",
    "# # Animate plot over time\n",
    "# for time_step in range(len(steps)):\n",
    "#     shell['tas'].data = steps[time_step][0,0,0]\n",
    "#     shell['tas'].plot.pcolormesh(ax=ax1,add_colorbar=False)\n",
    "#     ax1.set_title(f\"diffusion step {time_step}\")    \n",
    "#     camera.snap()\n",
    "# anim = camera.animate()\n",
    "# anim.save(f\"diffusion.gif\")\n",
    "\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(16, 6))\n",
    "container = []\n",
    "for time_step in range(len(steps)):\n",
    "    shell['tas'].data = steps[time_step][0,4]\n",
    "   # line = ax1.pcolormesh(steps[time_step][0,0,0])\n",
    "    line = shell['tas'].plot.pcolormesh(ax=ax1,add_colorbar=False)\n",
    "    title = ax1.text(0.5,1.05,\"Diffusion Step {}\".format(time_step), \n",
    "                    size=plt.rcParams[\"axes.titlesize\"],\n",
    "                    ha=\"center\", transform=ax1.transAxes, )\n",
    "    container.append([line, title])\n",
    "plt.title('')\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, container, interval=100, blit=True)\n",
    "ani.save(\"diffusion.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.lightning_module.metrics.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dcpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
